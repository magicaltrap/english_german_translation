{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "seq2seq-translation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magicaltrap/english_german_translation/blob/master/seq2seq_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQdli57wX7yw",
        "colab_type": "code",
        "outputId": "0b74b30c-df07-4850-8b41-0b90c5b123a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0hFVlow0Z-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "path_translation = \"/content/gdrive/My Drive/data/translation/\"\n",
        "path_translation_data = \"/content/gdrive/My Drive/data/translation/data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9U9owaXWcgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHxfuYsw6xrA",
        "colab_type": "text"
      },
      "source": [
        "# Methods for creating and loading Databunches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xoiPXk6Wcg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_collate(samples, pad_idx=1, pad_first=True, backwards=False):\n",
        "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
        "    samples = to_data(samples) #https://docs.fast.ai/torch_core.html#to_data #to their int value?\n",
        "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples]) #max length of a sentence in the dataset\n",
        "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx #samples x max_len of whole data \n",
        "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
        "    if backwards: pad_first = not pad_first\n",
        "    for i,s in enumerate(samples): #go through every sample\n",
        "        if pad_first: #padding tokens first then emb\n",
        "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1]) #row 0, 1, 2 (one sentence in each language each)\n",
        "        else:         \n",
        "            res_x[i,:len(s[0]):],res_y[i,:len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
        "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
        "    return res_x,res_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQB9EqKgWchL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqDataBunch(TextDataBunch):\n",
        "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
        "    @classmethod\n",
        "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1,\n",
        "               dl_tfms=None, pad_first=False, device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
        "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
        "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
        "        val_bs = ifnone(val_bs, bs)\n",
        "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
        "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
        "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
        "        dataloaders = [train_dl]\n",
        "        for ds in datasets[1:]:\n",
        "            lengths = [len(t) for t in ds.x.items]\n",
        "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
        "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
        "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flUxRvu2WchS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqTextList(TextList):\n",
        "    _bunch = Seq2SeqDataBunch\n",
        "    _label_cls = TextList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e1V3wpc4IAo",
        "colab_type": "text"
      },
      "source": [
        "## Load Databunch (137k) and Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0OlstPJ4QWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(path_translation_data, \"db1_137k_25sl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvdXW6fL4qbj",
        "colab_type": "code",
        "outputId": "b9d86b59-0316-4ef7-8acc-7db1844f6091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "data.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos to be sure , substantial progress has been made in the last 15 years , and efforts are being made to sustain it .</td>\n",
              "      <td>xxbos sicherlich wurden in den letzten fünfzehn jahren erhebliche fortschritte gemacht , und die bemühungen gehen weiter .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos despite a change of government in the netherlands since voluntary euthanasia was legalized , no effort has been made to repeal the measure .</td>\n",
              "      <td>xxbos trotz eines xxunk in den niederlanden seit der legalisierung der freiwilligen euthanasie , gab es keinerlei bemühungen diese maßnahme aufzuheben .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos and now , with the election results inciting the largest protests since the collapse of the soviet union , that hope is growing .</td>\n",
              "      <td>xxbos und jetzt , da das wahlergebnis die größten proteste seit dem zusammenbruch der sowjetunion hervorruft , wächst diese hoffnung noch weiter .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos this is a matter of human rights and basic values , and it is vital to peace and cohesion in societies across europe .</td>\n",
              "      <td>xxbos das ist eine frage der menschenrechte und der grundwerte und von entscheidender bedeutung für den frieden und zusammenhalt der gesellschaften in ganz europa .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos so mexico 's auto industry must make huge advances in productivity if it is to maintain the same wage level in the future .</td>\n",
              "      <td>xxbos wenn man daher in zukunft das einkommensniveau halten will , muss die mexikanische autoindustrie große produktivitätszuwächse aufweisen .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35mBRJj2WciS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_enc = torch.load(path_translation + 'en_emb_137k_25l.pth')\n",
        "emb_dec = torch.load(path_translation + 'de_emb_137k_25l.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3_7YEFAWciV",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhzTi2TtWciX",
        "colab_type": "text"
      },
      "source": [
        "### Encoders & Decoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RagejY9HWciZ",
        "colab_type": "text"
      },
      "source": [
        "The model in itself consists in an encoder and a decoder\n",
        "\n",
        "![Seq2seq model](https://github.com/fastai/course-nlp/blob/master/images/seq2seq.png?raw=1)\n",
        "\n",
        "<center><i>Diagram from Smerity's <a href=\"https://smerity.com/articles/2016/google_nmt_arch.html\">Peeking into the neural network architecture used for Google's Neural Machine Translation</a></i></center>\n",
        "\n",
        "The encoder is a recurrent neural net and we feed it our input sentence, producing an output (that we discard for now) and a hidden state.  A **hidden state** is the activations that come out of an RNN.\n",
        "\n",
        "That hidden state is then given to the decoder (an other RNN) which uses it in conjunction with the outputs it predicts to get produce the translation. We loop until the decoder produces a padding token (or at 25 iterations to make sure it's not an infinite loop at the beginning of training). We will use GRUs for both encoder decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E09LC4UWWcia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqRNN(nn.Module):\n",
        "    def __init__(self, emb_enc, emb_dec, \n",
        "                    nh, out_sl, \n",
        "                    nl=2, bos_idx=0, pad_idx=1):\n",
        "        super().__init__()\n",
        "        #sizes\n",
        "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
        "        self.bos_idx,self.pad_idx = bos_idx,pad_idx\n",
        "        self.em_sz_enc = emb_enc.embedding_dim #emb size: 300\n",
        "        self.em_sz_dec = emb_dec.embedding_dim #300\n",
        "        self.voc_sz_dec = emb_dec.num_embeddings #number of vocab emb: emb_dec.weight.data.shape[0]\n",
        "        \n",
        "        #embedding\n",
        "        self.emb_enc = emb_enc\n",
        "        self.emb_enc_drop = nn.Dropout(0.15)\n",
        "        \n",
        "        #Encoder\n",
        "        self.gru_enc = nn.GRU(self.em_sz_enc, nh, num_layers=nl, #GRU (em_sz_enc=300, nh=256, num_layers=2)\n",
        "                              dropout=0.25, batch_first=True) #setting num_layers=2 would mean stacking two GRUs together to form a stacked GRU, with the second GRU taking in outputs of the first GRU and computing the final results.\n",
        "        self.out_enc = nn.Linear(nh, self.em_sz_dec, bias=False) #nh=256, em_sz_dec=300 (initial input for decoder)\n",
        "        \n",
        "                \n",
        "        #Decoder\n",
        "        self.emb_dec = emb_dec\n",
        "        self.gru_dec = nn.GRU(self.em_sz_dec, self.em_sz_dec, num_layers=nl,  #input=300, output=300\n",
        "                              dropout=0.1, batch_first=True)\n",
        "        self.out_drop = nn.Dropout(0.35)\n",
        "        self.out = nn.Linear(self.em_sz_dec, self.voc_sz_dec) #300, vocab size decoder\n",
        "        self.out.weight.data = self.emb_dec.weight.data #the embedding matrix\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def encoder(self, bs, inp):\n",
        "        h = self.initHidden(bs) #initial start (empty)?\n",
        "        emb = self.emb_enc_drop(self.emb_enc(inp))  #embedding and then dropout\n",
        "        _, h = self.gru_enc(emb, h) #current emb + previous step + discard output\n",
        "        h = self.out_enc(h) #output of encoder (hidden state)\n",
        "        return h\n",
        "    \n",
        "    def decoder(self, dec_inp, h):\n",
        "        emb = self.emb_dec(dec_inp).unsqueeze(1) #embeddings of target sentence\n",
        "        outp, h = self.gru_dec(emb, h) #embedding+previous hidden state\n",
        "        outp = self.out(self.out_drop(outp[:,0])) #output is of size decoder vocab size (which word to pick, with probs)\n",
        "        return h, outp\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, inp):\n",
        "        bs, sl = inp.size() #batch size, sentence length\n",
        "        h = self.encoder(bs, inp) #input for encoder (batch size, input) output: hidden state for decoder\n",
        "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
        "        \n",
        "        res = []\n",
        "        for i in range(self.out_sl): #max sentence length\n",
        "            h, outp = self.decoder(dec_inp, h) #input for decoder\n",
        "            dec_inp = outp.max(1)[1] #pick the word with highest prob\n",
        "            res.append(outp)\n",
        "            if (dec_inp==self.pad_idx).all(): break\n",
        "        return torch.stack(res, dim=1)\n",
        "    \n",
        "    def initHidden(self, bs): return one_param(self).new_zeros(self.nl, bs, self.nh) #in Encoder: 2 (numb of layers=2, batch size, self.nh=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-oxWWOeWcif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb,yb = next(iter(data.valid_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57N8WwL5Wcih",
        "colab_type": "code",
        "outputId": "fef47350-8698-4816-fcda-d7d1b30e7bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "xb.shape #bs, max sentence length"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDh2SyNdWcii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn = Seq2SeqRNN(emb_enc, emb_dec, 256, 25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TPAD-QpZWcik",
        "colab_type": "code",
        "outputId": "70b73c00-210e-4888-c756-6ea67d440780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "rnn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqRNN(\n",
              "  (emb_enc): Embedding(33272, 300, padding_idx=1)\n",
              "  (emb_enc_drop): Dropout(p=0.15)\n",
              "  (gru_enc): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.25)\n",
              "  (out_enc): Linear(in_features=256, out_features=300, bias=False)\n",
              "  (emb_dec): Embedding(60000, 300, padding_idx=1)\n",
              "  (gru_dec): GRU(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (out_drop): Dropout(p=0.35)\n",
              "  (out): Linear(in_features=300, out_features=60000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI2aYBlHZOFj",
        "colab_type": "code",
        "outputId": "5fc295ff-4c3a-4973-8560-a763f8484c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "xb, xb.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[   2,   44,   26,  ...,   15,   86,   11],\n",
              "         [   2,   65,   10,  ...,   25, 3032,   11],\n",
              "         [   2,   27,   16,  ...,  501,  264,   11],\n",
              "         ...,\n",
              "         [   2,  576,   56,  ...,   11,  706,  706],\n",
              "         [   2,  155,   10,  ...,   61,  398,   11],\n",
              "         [   2,  347,   89,  ..., 5642,  896,   11]], device='cuda:0'),\n",
              " torch.Size([64, 25]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2LHKpBnWcin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h = rnn.encoder(64, xb.cpu())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7i_6eMXWcio",
        "colab_type": "code",
        "outputId": "30a9fe7e-0843-459b-8ef0-75e0832790ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "h.size() #number of layers, bs, emb_z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6ISI5pCWciq",
        "colab_type": "text"
      },
      "source": [
        "The loss pads output and target so that they are of the same size before using the usual flattened version of cross entropy. We do the same for accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5M35_eSWcit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_loss(out, targ, pad_idx=1):\n",
        "    bs,targ_len = targ.size()\n",
        "    _,out_len,vs = out.size()\n",
        "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
        "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
        "    return CrossEntropyFlat()(out, targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiwCzV5UWciv",
        "colab_type": "text"
      },
      "source": [
        "## Train our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqEWJ9wvWciv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, rnn, loss_func=seq2seq_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "WENPlSdMWciw",
        "colab_type": "code",
        "outputId": "d03723cc-cd6b-4c1a-b868-872787d3b8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay0yc_LsbQ9c",
        "colab_type": "code",
        "outputId": "1fbdb530-e5b3-40bd-e669-c3798fc2d3ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn2EqmmvbkOV",
        "colab_type": "code",
        "outputId": "a9a74b59-279c-4a3b-8132-7e3aafa96fc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.183660</td>\n",
              "      <td>7.437054</td>\n",
              "      <td>21:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.517251</td>\n",
              "      <td>6.377806</td>\n",
              "      <td>19:53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.264047</td>\n",
              "      <td>6.305460</td>\n",
              "      <td>20:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.947694</td>\n",
              "      <td>5.875203</td>\n",
              "      <td>20:33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBEhEz9UWci3",
        "colab_type": "text"
      },
      "source": [
        "Let's free up some RAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBei6s9vWci3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del de_vecs\n",
        "del en_vecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdN8wPABWci5",
        "colab_type": "text"
      },
      "source": [
        "As loss is not very interpretable, let's also look at the accuracy.  Again, we will add padding so that the output and target are of the same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNhsWT73Wci5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_acc(out, targ, pad_idx=1):\n",
        "    bs,targ_len = targ.size()\n",
        "    _,out_len,vs = out.size()\n",
        "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
        "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
        "    out = out.argmax(2)\n",
        "    return (out==targ).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9Vi-Cb5Wci7",
        "colab_type": "text"
      },
      "source": [
        "### Bleu metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvj8JyxYWci7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NGram():\n",
        "    def __init__(self, ngram, max_n=5000): self.ngram,self.max_n = ngram,max_n\n",
        "    def __eq__(self, other):\n",
        "        if len(self.ngram) != len(other.ngram): return False\n",
        "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
        "    def __hash__(self): return int(sum([o * self.max_n**i for i,o in enumerate(self.ngram)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEr8UJsXWci9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_grams(x, n, max_n=5000):\n",
        "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nYgCdQCWcjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_correct_ngrams(pred, targ, n, max_n=5000):\n",
        "    pred_grams,targ_grams = get_grams(pred, n, max_n=max_n),get_grams(targ, n, max_n=max_n)\n",
        "    pred_cnt,targ_cnt = Counter(pred_grams),Counter(targ_grams)\n",
        "    return sum([min(c, targ_cnt[g]) for g,c in pred_cnt.items()]),len(pred_grams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OuRk69RWcjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CorpusBLEU(Callback):\n",
        "    def __init__(self, vocab_sz):\n",
        "        self.vocab_sz = vocab_sz\n",
        "        self.name = 'bleu'\n",
        "    \n",
        "    def on_epoch_begin(self, **kwargs):\n",
        "        self.pred_len,self.targ_len,self.corrects,self.counts = 0,0,[0]*4,[0]*4\n",
        "    \n",
        "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
        "        last_output = last_output.argmax(dim=-1)\n",
        "        for pred,targ in zip(last_output.cpu().numpy(),last_target.cpu().numpy()):\n",
        "            self.pred_len += len(pred)\n",
        "            self.targ_len += len(targ)\n",
        "            for i in range(4):\n",
        "                c,t = get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
        "                self.corrects[i] += c\n",
        "                self.counts[i]   += t\n",
        "    \n",
        "    def on_epoch_end(self, last_metrics, **kwargs):\n",
        "        precs = [c/t for c,t in zip(self.corrects,self.counts)]\n",
        "        len_penalty = exp(1 - self.targ_len/self.pred_len) if self.pred_len < self.targ_len else 1\n",
        "        bleu = len_penalty * ((precs[0]*precs[1]*precs[2]*precs[3]) ** 0.25)\n",
        "        return add_metrics(last_metrics, bleu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cki3uDnIWcjE",
        "colab_type": "text"
      },
      "source": [
        "### Training with metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "98hccm7VWcjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, rnn, loss_func=seq2seq_loss, metrics=[seq2seq_acc, CorpusBLEU(len(data.y.vocab.itos))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "38Ndjk0aWcjH",
        "colab_type": "code",
        "outputId": "10a163ba-7586-4aff-c1cc-afa3fb6d163d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd9RB26hWcjI",
        "colab_type": "code",
        "outputId": "435d6c74-1184-422f-9e91-0df0fdcda829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAMKDLfTWcjK",
        "colab_type": "code",
        "outputId": "d1f94fd8-5915-4b4a-caec-f6355b020943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "learn.fit_one_cycle(4, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>seq2seq_acc</th>\n",
              "      <th>bleu</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.867053</td>\n",
              "      <td>5.825262</td>\n",
              "      <td>0.247242</td>\n",
              "      <td>0.167211</td>\n",
              "      <td>21:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.874644</td>\n",
              "      <td>5.845784</td>\n",
              "      <td>0.245721</td>\n",
              "      <td>0.166316</td>\n",
              "      <td>21:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.813367</td>\n",
              "      <td>5.695110</td>\n",
              "      <td>0.257717</td>\n",
              "      <td>0.174171</td>\n",
              "      <td>21:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.598033</td>\n",
              "      <td>5.671896</td>\n",
              "      <td>0.259412</td>\n",
              "      <td>0.175585</td>\n",
              "      <td>21:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in long_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2oLTV-HWcjO",
        "colab_type": "text"
      },
      "source": [
        "Let's see a few predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVSilTDJWcjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
        "    learn.model.eval()\n",
        "    inputs, targets, outputs = [],[],[]\n",
        "    with torch.no_grad():\n",
        "        for xb,yb in progress_bar(learn.dl(ds_type)):\n",
        "            out = learn.model(xb)\n",
        "            for x,y,z in zip(xb,yb,out):\n",
        "                inputs.append(learn.data.train_ds.x.reconstruct(x))\n",
        "                targets.append(learn.data.train_ds.y.reconstruct(y))\n",
        "                outputs.append(learn.data.train_ds.y.reconstruct(z.argmax(1)))\n",
        "    return inputs, targets, outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlhuxAPgWcjP",
        "colab_type": "code",
        "outputId": "dde5e282-a210-4319-aa64-36985bef0c21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "inputs, targets, outputs = get_predictions(learn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='240' class='' max='240', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [240/240 01:40<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsnOAtO-WcjR",
        "colab_type": "code",
        "outputId": "79a31dd9-03ba-4fc5-d00a-b6204a24daf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "inputs[700], targets[700], outputs[700]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos trump ’s simplistic , xenophobic rhetoric will also find a sympathetic audience among poles and hungarians who fear large - scale immigration .,\n",
              " Text xxbos trumps vereinfachende , xxunk rhetorik wird auch bei jenen polen und ungarn anklang finden , die sich vor umfangreicher zuwanderung fürchten .,\n",
              " Text xxbos trumps xxunk xxunk xxunk , , , , , , , , und und und und xxunk xxunk . .)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRsvcv_dWcjS",
        "colab_type": "code",
        "outputId": "0c534076-cfe1-40f6-baf5-afab372230e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "inputs[701], targets[701], outputs[701]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos my portal to the world of artificial intelligence is a narrow one : the more than xxunk - old game of chess .,\n",
              " Text xxbos mein eigener zugang zur welt der künstlichen intelligenz ist ein eng xxunk : das über 500 jahre alte xxunk schach .,\n",
              " Text xxbos ich der der der der der der der der xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofz1y4YwWcjX",
        "colab_type": "code",
        "outputId": "bb39d758-eae4-4460-b266-c7884a867180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "inputs[2000], targets[2000], outputs[2000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos the transition from autocracy to democracy in the middle east is likely to be bumpy and unstable , at best .,\n",
              " Text xxbos der übergang von der autokratie zur demokratie i m nahen osten wird wahrscheinlich holprig und instabil verlaufen – bestenfalls .,\n",
              " Text xxbos der der der nahen osten osten osten osten osten osten osten osten und und und osten . .)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyBn3UDBWcjU",
        "colab_type": "code",
        "outputId": "7385a4a5-7123-4d9e-ef5a-2552e7584156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "inputs[2513], targets[2513], outputs[2513]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos but it is time to go further and begin to lobby aggressively for faster financial liberalization in the developing world .,\n",
              " Text xxbos es ist allerdings an der zeit , sich darüber hinaus mit mehr nachdruck für eine raschere finanzliberalisierung in den entwicklungsländern einzusetzen .,\n",
              " Text xxbos aber es es zeit zeit , , , , die die die die in in zu zu zu .)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THIZ6c_cWcjY",
        "colab_type": "text"
      },
      "source": [
        "It's usually beginning well, but falls into repeated words at the end of the question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TaVAFlAWcjY",
        "colab_type": "text"
      },
      "source": [
        "## Teacher forcing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MXA-XAFWcjZ",
        "colab_type": "text"
      },
      "source": [
        "One way to help training is to help the decoder by feeding it the real targets instead of its predictions (if it starts with wrong words, it's very unlikely to give us the right translation). We do that all the time at the beginning, then progressively reduce the amount of teacher forcing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XgzAKhNWcjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TeacherForcing(LearnerCallback):\n",
        "    \n",
        "    def __init__(self, learn, end_epoch):\n",
        "        super().__init__(learn)\n",
        "        self.end_epoch = end_epoch\n",
        "    \n",
        "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
        "        if train: return {'last_input': [last_input, last_target]}\n",
        "    \n",
        "    def on_epoch_begin(self, epoch, **kwargs):\n",
        "        self.learn.model.pr_force = 1 - epoch/self.end_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VorsnTWqWcjc",
        "colab_type": "text"
      },
      "source": [
        "We will add the following code to our `forward` method:\n",
        "\n",
        "```\n",
        "    if (targ is not None) and (random.random()<self.pr_force):\n",
        "        if i>=targ.shape[1]: break\n",
        "        dec_inp = targ[:,i]\n",
        "```\n",
        "Additionally, `forward` will take an additional argument of `target`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkcWidi-Wcjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqRNN_tf(nn.Module):\n",
        "    def __init__(self, emb_enc, emb_dec, nh, out_sl, nl=2, bos_idx=0, pad_idx=1):\n",
        "        super().__init__()\n",
        "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
        "        self.bos_idx,self.pad_idx = bos_idx,pad_idx\n",
        "        self.em_sz_enc = emb_enc.embedding_dim\n",
        "        self.em_sz_dec = emb_dec.embedding_dim\n",
        "        self.voc_sz_dec = emb_dec.num_embeddings\n",
        "                 \n",
        "        self.emb_enc = emb_enc\n",
        "        self.emb_enc_drop = nn.Dropout(0.15)\n",
        "        self.gru_enc = nn.GRU(self.em_sz_enc, nh, num_layers=nl,\n",
        "                              dropout=0.25, batch_first=True)\n",
        "        self.out_enc = nn.Linear(nh, self.em_sz_dec, bias=False)\n",
        "        \n",
        "        self.emb_dec = emb_dec\n",
        "        self.gru_dec = nn.GRU(self.em_sz_dec, self.em_sz_dec, num_layers=nl,\n",
        "                              dropout=0.1, batch_first=True)\n",
        "        self.out_drop = nn.Dropout(0.35)\n",
        "        self.out = nn.Linear(self.em_sz_dec, self.voc_sz_dec)\n",
        "        self.out.weight.data = self.emb_dec.weight.data\n",
        "        self.pr_force = 0.\n",
        "        \n",
        "    def encoder(self, bs, inp):\n",
        "        h = self.initHidden(bs)\n",
        "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
        "        _, h = self.gru_enc(emb, h)\n",
        "        h = self.out_enc(h)\n",
        "        return h\n",
        "    \n",
        "    def decoder(self, dec_inp, h):\n",
        "        emb = self.emb_dec(dec_inp).unsqueeze(1)\n",
        "        outp, h = self.gru_dec(emb, h)\n",
        "        outp = self.out(self.out_drop(outp[:,0]))\n",
        "        return h, outp\n",
        "            \n",
        "    def forward(self, inp, targ=None):\n",
        "        bs, sl = inp.size()\n",
        "        h = self.encoder(bs, inp)\n",
        "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
        "        \n",
        "        res = []\n",
        "        for i in range(self.out_sl):\n",
        "            h, outp = self.decoder(dec_inp, h)\n",
        "            res.append(outp)\n",
        "            dec_inp = outp.max(1)[1]\n",
        "            if (dec_inp==self.pad_idx).all(): break\n",
        "            if (targ is not None) and (random.random()<self.pr_force):\n",
        "                if i>=targ.shape[1]: continue\n",
        "                dec_inp = targ[:,i]\n",
        "        return torch.stack(res, dim=1)\n",
        "\n",
        "    def initHidden(self, bs): return one_param(self).new_zeros(self.nl, bs, self.nh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl20xfJcWcjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_enc = torch.load(path_translation + 'en_emb_137k_25l.pth')\n",
        "emb_dec = torch.load(path_translation + 'de_emb_137k_25l.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImjiE2XRBrgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(path_translation_data, \"db1_137k_25sl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO4RW6-QWcjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_tf = Seq2SeqRNN_tf(emb_enc, emb_dec, 256, 30)\n",
        "\n",
        "learn_tf = Learner(data, rnn_tf, loss_func=seq2seq_loss, metrics=[seq2seq_acc, CorpusBLEU(len(data.y.vocab.itos))],\n",
        "               callback_fns=partial(TeacherForcing, end_epoch=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "T97IsSmhWcjh",
        "colab_type": "code",
        "outputId": "45092480-fff0-4c13-d17d-f0185d96285d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "learn_tf.lr_find()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izFZmmcUWcjj",
        "colab_type": "code",
        "outputId": "9aef0be8-1755-460f-bcf5-d34db331bdca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "learn_tf.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKTOKQhEROqcgkBEpM4pCERE6tz/B2FEkfeVct4eAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igc2952b9hT_",
        "colab_type": "text"
      },
      "source": [
        "I'm trying out a few different learning rates here. The loss/learning rate curve is not easily interpretable, so we need to experiment a bit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvA8SAReYID5",
        "colab_type": "code",
        "outputId": "7fb65112-ac7c-4470-b517-8452e150fe0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "learn_tf.fit_one_cycle(3, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>seq2seq_acc</th>\n",
              "      <th>bleu</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.243083</td>\n",
              "      <td>4.877440</td>\n",
              "      <td>0.413164</td>\n",
              "      <td>0.181102</td>\n",
              "      <td>30:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.608022</td>\n",
              "      <td>5.998855</td>\n",
              "      <td>0.248835</td>\n",
              "      <td>0.171576</td>\n",
              "      <td>24:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.079815</td>\n",
              "      <td>6.600609</td>\n",
              "      <td>0.206655</td>\n",
              "      <td>0.153055</td>\n",
              "      <td>21:30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in long_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsWJM9-KCVTv",
        "colab_type": "code",
        "outputId": "d7f87d06-1069-4a18-8f50-df6bcfbefb41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "learn_tf.fit_one_cycle(4, 5e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>seq2seq_acc</th>\n",
              "      <th>bleu</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.086277</td>\n",
              "      <td>6.145834</td>\n",
              "      <td>0.334220</td>\n",
              "      <td>0.215677</td>\n",
              "      <td>28:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.992745</td>\n",
              "      <td>5.950576</td>\n",
              "      <td>0.263096</td>\n",
              "      <td>0.201561</td>\n",
              "      <td>23:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.293686</td>\n",
              "      <td>6.328215</td>\n",
              "      <td>0.222104</td>\n",
              "      <td>0.174188</td>\n",
              "      <td>22:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.323520</td>\n",
              "      <td>6.390608</td>\n",
              "      <td>0.216423</td>\n",
              "      <td>0.152178</td>\n",
              "      <td>20:43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in long_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1nEzgUl6HrZ",
        "colab_type": "code",
        "outputId": "8b946483-80f9-4e31-a944-63e2e522a8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "learn_tf.fit_one_cycle(4, 8e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>seq2seq_acc</th>\n",
              "      <th>bleu</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.704269</td>\n",
              "      <td>5.146167</td>\n",
              "      <td>0.352601</td>\n",
              "      <td>0.134110</td>\n",
              "      <td>24:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.517701</td>\n",
              "      <td>6.070536</td>\n",
              "      <td>0.261921</td>\n",
              "      <td>0.219345</td>\n",
              "      <td>23:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.184779</td>\n",
              "      <td>6.034648</td>\n",
              "      <td>0.242406</td>\n",
              "      <td>0.187292</td>\n",
              "      <td>23:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.939337</td>\n",
              "      <td>6.043734</td>\n",
              "      <td>0.240516</td>\n",
              "      <td>0.165269</td>\n",
              "      <td>21:56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in long_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xQx4xaASWcjk",
        "colab_type": "code",
        "outputId": "992c65ed-5c4e-4f56-cdfa-c3c09802328c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "hlearn_tf.fit_one_cycle(4, 1e-3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>seq2seq_acc</th>\n",
              "      <th>bleu</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.708332</td>\n",
              "      <td>6.911163</td>\n",
              "      <td>0.273896</td>\n",
              "      <td>0.218682</td>\n",
              "      <td>27:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.606237</td>\n",
              "      <td>5.657241</td>\n",
              "      <td>0.284641</td>\n",
              "      <td>0.214021</td>\n",
              "      <td>23:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.905083</td>\n",
              "      <td>5.947309</td>\n",
              "      <td>0.248738</td>\n",
              "      <td>0.192882</td>\n",
              "      <td>23:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.866989</td>\n",
              "      <td>6.014758</td>\n",
              "      <td>0.242266</td>\n",
              "      <td>0.165167</td>\n",
              "      <td>20:45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in long_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlJjlksA-C8E",
        "colab_type": "text"
      },
      "source": [
        "With Teacher's Forcing we can improve our Bleu scores to ~0.21. Our outputs with TF (below) are bit better but still far from acceptable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvnWG_lQWcjm",
        "colab_type": "code",
        "outputId": "0882e009-3373-4922-c97e-66268993bea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "inputs, targets, outputs = get_predictions(learn_tf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='240' class='' max='240', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [240/240 01:37<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx36ds1EWcjp",
        "colab_type": "code",
        "outputId": "bb16e6ce-11d1-4e03-d399-8f815f4ac74f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "inputs[700],targets[700],outputs[700]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos trump ’s simplistic , xenophobic rhetoric will also find a sympathetic audience among poles and hungarians who fear large - scale immigration .,\n",
              " Text xxbos trumps vereinfachende , xxunk rhetorik wird auch bei jenen polen und ungarn anklang finden , die sich vor umfangreicher zuwanderung fürchten .,\n",
              " Text xxbos trumps xxunk xxunk xxunk , , , xxunk xxunk und , , , , und und xxunk xxunk .)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-VgtZhS3-KW",
        "colab_type": "code",
        "outputId": "1ca92ba8-d690-42b5-a563-e5225cd976fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "inputs[701],targets[701],outputs[701]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos my portal to the world of artificial intelligence is a narrow one : the more than xxunk - old game of chess .,\n",
              " Text xxbos mein eigener zugang zur welt der künstlichen intelligenz ist ein eng xxunk : das über 500 jahre alte xxunk schach .,\n",
              " Text xxbos meine xxunk der der der der ist ist ein , , , , xxunk xxunk xxunk xxunk .)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B0XVuPmWcjt",
        "colab_type": "code",
        "outputId": "b3673e2a-a371-481d-e446-065d4d438fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "inputs[2000], targets[2000], outputs[2000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos the transition from autocracy to democracy in the middle east is likely to be bumpy and unstable , at best .,\n",
              " Text xxbos der übergang von der autokratie zur demokratie i m nahen osten wird wahrscheinlich holprig und instabil verlaufen – bestenfalls .,\n",
              " Text xxbos der kampf der der in in in osten in osten ist und und und und und .)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F13s-oMmWcjq",
        "colab_type": "code",
        "outputId": "ea467c8f-a056-488c-ad3d-28a54b6af5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "inputs[2513], targets[2513], outputs[2513]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos but it is time to go further and begin to lobby aggressively for faster financial liberalization in the developing world .,\n",
              " Text xxbos es ist allerdings an der zeit , sich darüber hinaus mit mehr nachdruck für eine raschere finanzliberalisierung in den entwicklungsländern einzusetzen .,\n",
              " Text xxbos es ist es zeit zeit , , , und , die die die die die die der zu)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    }
  ]
}