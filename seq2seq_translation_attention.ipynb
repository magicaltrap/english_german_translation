{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "seq2seq-translation-attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magicaltrap/english_german_translation/blob/master/seq2seq_translation_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEKRYTfzJZk6",
        "colab_type": "code",
        "outputId": "2a153de4-d32d-4384-cf54-9bafd1579e8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jAfawCvJbac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "path_translation = \"/content/gdrive/My Drive/data/translation/\"\n",
        "path_translation_data = \"/content/gdrive/My Drive/data/translation/data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMC_8bk-IUzV",
        "colab_type": "text"
      },
      "source": [
        "# Seq2Seq Translation with Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08Dto2JpIUzW",
        "colab_type": "text"
      },
      "source": [
        "Attention is a technique that uses the output of our encoder: instead of discarding it entirely, we use it with our hidden state to pay attention to specific words in the input sentence for the predictions in the output sentence. Specifically, we compute attention weights, then add to the input of the decoder the linear combination of the output of the encoder, with those attention weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUbjvx6aIUzX",
        "colab_type": "text"
      },
      "source": [
        "A nice illustration of attention comes from [this blog post](http://jalammar.github.io/illustrated-transformer/) by Jay Alammar (visualization originally from [Tensor2Tensor notebook](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb)):\n",
        "\n",
        "<img src=\"https://github.com/fastai/course-nlp/blob/master/images/alammar-attention.png?raw=1\" alt=\"attention\" style=\"width: 60%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaSICFbxIUzY",
        "colab_type": "text"
      },
      "source": [
        "A second things that might help is to use a bidirectional model for the encoder. We set the `bidrectional` parameter to `True` for our GRU encoder, and double the number of inputs to the linear output layer of the encoder.\n",
        "\n",
        "Also, we now need to set our hidden state:\n",
        "\n",
        "```\n",
        "hid = hid.view(2,self.n_layers, bs, self.n_hid).permute(1,2,0,3).contiguous()\n",
        "hid = self.out_enc(self.hid_dp(hid).view(self.n_layers, bs, 2*self.n_hid))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mXxGtSIIUzZ",
        "colab_type": "text"
      },
      "source": [
        "### Code to re-run from start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_i6YhD5IUzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPaagg-jIUzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_collate(samples:BatchSamples, pad_idx:int=1, pad_first:bool=True, backwards:bool=False) -> Tuple[LongTensor, LongTensor]:\n",
        "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
        "    samples = to_data(samples)\n",
        "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
        "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
        "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
        "    if backwards: pad_first = not pad_first\n",
        "    for i,s in enumerate(samples):\n",
        "        if pad_first: \n",
        "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
        "        else:         \n",
        "            res_x[i,:len(s[0])],res_y[i,:len(s[1])] = LongTensor(s[0]),LongTensor(s[1])\n",
        "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
        "    return res_x,res_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV_ALZVJIUzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqDataBunch(TextDataBunch):\n",
        "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
        "    @classmethod\n",
        "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1,\n",
        "               dl_tfms=None, pad_first=False, device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
        "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
        "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
        "        val_bs = ifnone(val_bs, bs)\n",
        "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
        "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
        "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
        "        dataloaders = [train_dl]\n",
        "        for ds in datasets[1:]:\n",
        "            lengths = [len(t) for t in ds.x.items]\n",
        "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
        "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
        "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP50drnvIUzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqTextList(TextList):\n",
        "    _bunch = Seq2SeqDataBunch\n",
        "    _label_cls = TextList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6t5ZpQtIUzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(path_translation_data, \"db1_137k_25sl\") #comma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECRZV3xXIUz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_enc = torch.load(path_translation + 'en_emb_137k_25l.pth')\n",
        "emb_dec = torch.load(path_translation + 'de_emb_137k_25l.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCHXiftmIU0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_loss(out, targ, pad_idx=1):\n",
        "    bs,targ_len = targ.size()\n",
        "    _,out_len,vs = out.size()\n",
        "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
        "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
        "    return CrossEntropyFlat()(out, targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCJZ8t2jIU0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq_acc(out, targ, pad_idx=1):\n",
        "    bs,targ_len = targ.size()\n",
        "    _,out_len,vs = out.size()\n",
        "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
        "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
        "    out = out.argmax(2)\n",
        "    return (out==targ).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQzaxa0GIU0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NGram():\n",
        "    def __init__(self, ngram, max_n=5000): self.ngram,self.max_n = ngram,max_n\n",
        "    def __eq__(self, other):\n",
        "        if len(self.ngram) != len(other.ngram): return False\n",
        "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
        "    def __hash__(self): return int(sum([o * self.max_n**i for i,o in enumerate(self.ngram)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MndcLHX4IU0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_grams(x, n, max_n=5000):\n",
        "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICJfcDLTIU0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_correct_ngrams(pred, targ, n, max_n=5000):\n",
        "    pred_grams,targ_grams = get_grams(pred, n, max_n=max_n),get_grams(targ, n, max_n=max_n)\n",
        "    pred_cnt,targ_cnt = Counter(pred_grams),Counter(targ_grams)\n",
        "    return sum([min(c, targ_cnt[g]) for g,c in pred_cnt.items()]),len(pred_grams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iAiMuD9IU0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
        "    learn.model.eval()\n",
        "    inputs, targets, outputs = [],[],[]\n",
        "    with torch.no_grad():\n",
        "        for xb,yb in progress_bar(learn.dl(ds_type)):\n",
        "            out = learn.model(xb)\n",
        "            for x,y,z in zip(xb,yb,out):\n",
        "                inputs.append(learn.data.train_ds.x.reconstruct(x))\n",
        "                targets.append(learn.data.train_ds.y.reconstruct(y))\n",
        "                outputs.append(learn.data.train_ds.y.reconstruct(z.argmax(1)))\n",
        "    return inputs, targets, outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb9Lt5yaIU0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CorpusBLEU(Callback):\n",
        "    def __init__(self, vocab_sz):\n",
        "        self.vocab_sz = vocab_sz\n",
        "        self.name = 'bleu'\n",
        "    \n",
        "    def on_epoch_begin(self, **kwargs):\n",
        "        self.pred_len,self.targ_len,self.corrects,self.counts = 0,0,[0]*4,[0]*4\n",
        "    \n",
        "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
        "        last_output = last_output.argmax(dim=-1)\n",
        "        for pred,targ in zip(last_output.cpu().numpy(),last_target.cpu().numpy()):\n",
        "            self.pred_len += len(pred)\n",
        "            self.targ_len += len(targ)\n",
        "            for i in range(4):\n",
        "                c,t = get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
        "                self.corrects[i] += c\n",
        "                self.counts[i]   += t\n",
        "    \n",
        "    def on_epoch_end(self, last_metrics, **kwargs):\n",
        "        precs = [c/t for c,t in zip(self.corrects,self.counts)]\n",
        "        len_penalty = exp(1 - self.targ_len/self.pred_len) if self.pred_len < self.targ_len else 1\n",
        "        bleu = len_penalty * ((precs[0]*precs[1]*precs[2]*precs[3]) ** 0.25)\n",
        "        return add_metrics(last_metrics, bleu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TohoK6QDIU0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TeacherForcing(LearnerCallback):\n",
        "    def __init__(self, learn, end_epoch):\n",
        "        super().__init__(learn)\n",
        "        self.end_epoch = end_epoch\n",
        "    \n",
        "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
        "        if train: return {'last_input': [last_input, last_target]}\n",
        "    \n",
        "    def on_epoch_begin(self, epoch, **kwargs):\n",
        "        self.learn.model.pr_force = 1 - epoch/self.end_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVGJKp0UIU0W",
        "colab_type": "text"
      },
      "source": [
        "### Implementing attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz0fVilbIU0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2SeqRNN_attn(nn.Module):\n",
        "    def __init__(self, emb_enc, emb_dec, nh, out_sl, nl=2, bos_idx=0, pad_idx=1):\n",
        "        super().__init__()\n",
        "        self.nl,self.nh,self.out_sl,self.pr_force = nl,nh,out_sl,1\n",
        "        self.bos_idx,self.pad_idx = bos_idx,pad_idx\n",
        "        self.emb_enc,self.emb_dec = emb_enc,emb_dec\n",
        "        self.emb_sz_enc,self.emb_sz_dec = emb_enc.embedding_dim,emb_dec.embedding_dim\n",
        "        self.voc_sz_dec = emb_dec.num_embeddings\n",
        "                 \n",
        "        self.emb_enc_drop = nn.Dropout(0.15)\n",
        "        self.gru_enc = nn.GRU(self.emb_sz_enc, nh, num_layers=nl, dropout=0.25, \n",
        "                              batch_first=True, bidirectional=True)\n",
        "        self.out_enc = nn.Linear(2*nh, self.emb_sz_dec, bias=False)\n",
        "        \n",
        "        self.gru_dec = nn.GRU(self.emb_sz_dec + 2*nh, self.emb_sz_dec, num_layers=nl,\n",
        "                              dropout=0.1, batch_first=True)\n",
        "        self.out_drop = nn.Dropout(0.35)\n",
        "        self.out = nn.Linear(self.emb_sz_dec, self.voc_sz_dec)\n",
        "        self.out.weight.data = self.emb_dec.weight.data\n",
        "        \n",
        "        self.enc_att = nn.Linear(2*nh, self.emb_sz_dec, bias=False)\n",
        "        self.hid_att = nn.Linear(self.emb_sz_dec, self.emb_sz_dec)\n",
        "        self.V =  self.init_param(self.emb_sz_dec)\n",
        "        \n",
        "    def encoder(self, bs, inp):\n",
        "        h = self.initHidden(bs)\n",
        "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
        "        enc_out, hid = self.gru_enc(emb, 2*h)\n",
        "        \n",
        "        pre_hid = hid.view(2, self.nl, bs, self.nh).permute(1,2,0,3).contiguous()\n",
        "        pre_hid = pre_hid.view(self.nl, bs, 2*self.nh)\n",
        "        hid = self.out_enc(pre_hid)\n",
        "        return hid,enc_out\n",
        "    \n",
        "    def decoder(self, dec_inp, hid, enc_att, enc_out):\n",
        "        hid_att = self.hid_att(hid[-1])\n",
        "        # we have put enc_out and hid through linear layers\n",
        "        u = torch.tanh(enc_att + hid_att[:,None])\n",
        "        # we want to learn the importance of each time step\n",
        "        attn_wgts = F.softmax(u @ self.V, 1)\n",
        "        # weighted average of enc_out (which is the output at every time step)\n",
        "        ctx = (attn_wgts[...,None] * enc_out).sum(1)\n",
        "        emb = self.emb_dec(dec_inp)\n",
        "        # concatenate decoder embedding with context (we could have just\n",
        "        # used the hidden state that came out of the decoder, if we weren't\n",
        "        # using attention)\n",
        "        outp, hid = self.gru_dec(torch.cat([emb, ctx], 1)[:,None], hid)\n",
        "        outp = self.out(self.out_drop(outp[:,0]))\n",
        "        return hid, outp\n",
        "        \n",
        "    def show(self, nm,v):\n",
        "        if False: print(f\"{nm}={v[nm].shape}\")\n",
        "        \n",
        "    def forward(self, inp, targ=None):\n",
        "        bs, sl = inp.size()\n",
        "        hid,enc_out = self.encoder(bs, inp)\n",
        "#        self.show(\"hid\",vars())\n",
        "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
        "        enc_att = self.enc_att(enc_out)\n",
        "        \n",
        "        res = []\n",
        "        for i in range(self.out_sl):\n",
        "            hid, outp = self.decoder(dec_inp, hid, enc_att, enc_out)\n",
        "            res.append(outp)\n",
        "            dec_inp = outp.max(1)[1]\n",
        "            if (dec_inp==self.pad_idx).all(): break\n",
        "            if (targ is not None) and (random.random()<self.pr_force):\n",
        "                if i>=targ.shape[1]: continue\n",
        "                dec_inp = targ[:,i]\n",
        "        return torch.stack(res, dim=1)\n",
        "\n",
        "    def initHidden(self, bs): return one_param(self).new_zeros(2*self.nl, bs, self.nh)\n",
        "    def init_param(self, *sz): return nn.Parameter(torch.randn(sz)/math.sqrt(sz[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-JIrjaOJIU0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Seq2SeqRNN_attn(emb_enc, emb_dec, 256, 30)\n",
        "learn = Learner(data, model, loss_func=seq2seq_loss, metrics=[seq2seq_acc, CorpusBLEU(len(data.y.vocab.itos))],\n",
        "                callback_fns=partial(TeacherForcing, end_epoch=30))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "GmMTXfw_IU0g",
        "colab_type": "code",
        "outputId": "d5d698fa-bcec-4d56-a9d2-c63002a729ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igJs_bioMm-K",
        "colab_type": "code",
        "outputId": "ef66d7f0-35e2-4ae9-e061-c44c3cfc789a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwMxqLksS9ZX",
        "colab_type": "code",
        "outputId": "81df44cf-7fa8-40b7-b96b-ca4c46bec487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "learn.fit_one_cycle(6, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>seq2seq_acc</th>\n",
              "      <th>bleu</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>9.300254</td>\n",
              "      <td>8.817511</td>\n",
              "      <td>0.043869</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>32:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.435048</td>\n",
              "      <td>6.164268</td>\n",
              "      <td>0.259499</td>\n",
              "      <td>0.200800</td>\n",
              "      <td>30:29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.101758</td>\n",
              "      <td>5.744478</td>\n",
              "      <td>0.286845</td>\n",
              "      <td>0.203242</td>\n",
              "      <td>25:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.991771</td>\n",
              "      <td>5.475636</td>\n",
              "      <td>0.320038</td>\n",
              "      <td>0.213520</td>\n",
              "      <td>25:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.895970</td>\n",
              "      <td>5.414505</td>\n",
              "      <td>0.318583</td>\n",
              "      <td>0.211358</td>\n",
              "      <td>25:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.952050</td>\n",
              "      <td>5.452516</td>\n",
              "      <td>0.313406</td>\n",
              "      <td>0.211178</td>\n",
              "      <td>25:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in long_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5xWy1O2IU0n",
        "colab_type": "code",
        "outputId": "751d6449-7237-4646-af62-46c5e4027c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "inputs, targets, outputs = get_predictions(learn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='240' class='' max='240', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [240/240 01:47<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHwMHw6FIU0p",
        "colab_type": "code",
        "outputId": "e8ec2614-402e-4056-a3df-169e692a5e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "inputs[700], targets[700], outputs[700]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos trump ’s simplistic , xenophobic rhetoric will also find a sympathetic audience among poles and hungarians who fear large - scale immigration .,\n",
              " Text xxbos trumps vereinfachende , xxunk rhetorik wird auch bei jenen polen und ungarn anklang finden , die sich vor umfangreicher zuwanderung fürchten .,\n",
              " Text xxbos die xxunk xxunk , die xxunk , die xxunk , die xxunk und xxunk und xxunk und xxunk .)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLVLhPWCIU0r",
        "colab_type": "code",
        "outputId": "d9a6e0fb-cde9-4f52-8fe5-158126e23c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "inputs[701], targets[701], outputs[701]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos my portal to the world of artificial intelligence is a narrow one : the more than xxunk - old game of chess .,\n",
              " Text xxbos mein eigener zugang zur welt der künstlichen intelligenz ist ein eng xxunk : das über 500 jahre alte xxunk schach .,\n",
              " Text xxbos die der der der der der der der xxunk , die xxunk , die xxunk xxunk xxunk .)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW3m2I-p5wgW",
        "colab_type": "code",
        "outputId": "29d6d888-8b97-459c-9827-cc16b19a5417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "inputs[2000], targets[2000], outputs[2000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos the transition from autocracy to democracy in the middle east is likely to be bumpy and unstable , at best .,\n",
              " Text xxbos der übergang von der autokratie zur demokratie i m nahen osten wird wahrscheinlich holprig und instabil verlaufen – bestenfalls .,\n",
              " Text xxbos die der der der der der der in der der in der der in der xxunk , , , die zu zu .)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mWs0sbH5vHX",
        "colab_type": "code",
        "outputId": "3ce5606c-c9d6-4d54-f996-e98f09ae3482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "inputs[2513], targets[2513], outputs[2513]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Text xxbos but it is time to go further and begin to lobby aggressively for faster financial liberalization in the developing world .,\n",
              " Text xxbos es ist allerdings an der zeit , sich darüber hinaus mit mehr nachdruck für eine raschere finanzliberalisierung in den entwicklungsländern einzusetzen .,\n",
              " Text xxbos aber ist es , , die zu und und die zu und zu zu zu zu zu zu zu .)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}